---
layout: post
title: December Aliveline - Day 3
date: 2025-12-04
categories: alivelines
---
# Day 3 (12/4)

There is a "minimum description length" principle in ML, which is the idea that you don't want the weights to have too much information (? I don't really understand this that well tbh).

Is there a similar principle at play in brains? Do simpler tasks tend to activate a smaller population of neurons?
	We could answer this directly in C Elegans. But I doubt it's the case that it's smaller in direct size, it's more that the manifold geometry of the activation is simpler. But what does that mean?

The IL-17 cytokine as a neuromodulator paper makes me think that we don't understand the biology well enough yet to know the full space of things that can affect the brain, even for C Elegans. So it's unclear how valuable formalizing a hypothesis that more neuromodulators = more representational capacity is right now?

I really want to see a visualization of the dynamics of a connectome as it does a task. Time to download OpenWorm. Welp it took a lil time and it simulated like 10 seconds of the worm? Plus I don't see a connectome viz, just pictures of potentials/calcium/etc across neurons and muscles. Hmm.

Today is a pretty low energy day, did not sleep well for 2 nights. That's fine. Remove all pressure to get something done today, it's all good. This bug infestation fighting has been taking a ton of time and mental energy the last day.


It does seem like a more dynamical systems approach to cognition and how the brain works would be way more fruitful than any static views. In other words, you can't separate mind from subject (a la Democracy and Education) – cognition is a joint process between the mind, body, and the environment.

